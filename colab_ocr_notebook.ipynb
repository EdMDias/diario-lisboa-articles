{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Di√°rio de Lisboa - OCR Processing on Google Colab\n",
    "\n",
    "**Purpose**: Process newspaper scans with DOTS OCR using Colab's free GPU\n",
    "\n",
    "**Setup**:\n",
    "1. Runtime > Change runtime type > **GPU (T4)** > Save\n",
    "2. Upload newspaper scans to Google Drive\n",
    "3. Run all cells\n",
    "\n",
    "**Note**: Free Colab has 12-hour session limit and ~15GB VRAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"Execution started: {datetime.now()}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\n‚úÖ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"\\n‚ùå WARNING: GPU not available, OCR will be VERY slow\")\n",
    "    print(\"   Go to: Runtime > Change runtime type > GPU\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"\\nDevice: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Configure paths - CHANGE THESE TO MATCH YOUR DRIVE STRUCTURE\n",
    "DRIVE_BASE = '/content/drive/MyDrive/diario-lisboa'\n",
    "DATA_DIR = f'{DRIVE_BASE}/data'  # Where your newspaper scans are\n",
    "OUTPUT_DIR = f'{DRIVE_BASE}/ocr_output'  # Where OCR results will be saved\n",
    "\n",
    "print(f\"‚úÖ Google Drive mounted\")\n",
    "print(f\"   Data directory: {DATA_DIR}\")\n",
    "print(f\"   Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install DOTS OCR and dependencies\nprint(\"Installing dependencies (this takes ~3-5 minutes)...\")\n\n# Install PyTorch with CUDA support (usually pre-installed in Colab)\n!pip install -q torch torchvision torchaudio\n\n# Install transformers and dependencies\n!pip install -q transformers>=4.45.0 accelerate>=0.21.0\n!pip install -q qwen-vl-utils Pillow tqdm\n\n# Install DOTS OCR - we'll install dependencies manually to avoid flash-attn\nprint(\"\\nInstalling DOTS OCR dependencies...\")\n!pip install -q tikzplotlib timm einops\n\n# Clone and install DOTS OCR without flash-attn\nprint(\"Installing DOTS OCR (without flash-attention)...\")\n!git clone -q https://github.com/rednote-hilab/dots.ocr.git /tmp/dots_ocr 2>&1 | grep -v \"Cloning\"\n\n# Create a custom setup without flash-attn\nimport os\nos.chdir('/tmp/dots_ocr')\n\n# Install without dependencies first, then we control what gets installed\n!pip install -q --no-deps -e .\n\nprint(\"\\n‚úÖ All dependencies installed (flash-attention skipped for Colab compatibility)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download DOTS OCR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from transformers import AutoModelForCausalLM, AutoProcessor\nimport torch\nimport warnings\n\nMODEL_ID = \"rednote-hilab/dots.ocr\"\n\nprint(f\"Loading DOTS OCR model: {MODEL_ID}\")\nprint(\"This will download ~8-10GB on first run (cached for future runs)\")\nprint(\"Please wait...\\n\")\n\n# Suppress flash attention warnings\nwarnings.filterwarnings('ignore', message='.*flash attention.*')\n\n# Load model (without flash_attention_2 for Colab compatibility)\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_ID,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n    trust_remote_code=True,\n    # Note: Using eager attention instead of flash_attention_2 for Colab\n)\n\n# Load processor - use Qwen2VLProcessor directly to avoid video processor issue\ntry:\n    from transformers import Qwen2VLProcessor\n    processor = Qwen2VLProcessor.from_pretrained(\n        MODEL_ID,\n        trust_remote_code=True\n    )\nexcept:\n    # Fallback to AutoProcessor if Qwen2VLProcessor not available\n    processor = AutoProcessor.from_pretrained(\n        MODEL_ID,\n        trust_remote_code=True\n    )\n\nprint(\"\\n‚úÖ Model loaded successfully\")\nprint(f\"   Model parameters: {sum(p.numel() for p in model.parameters()) / 1e9:.2f}B\")\nprint(f\"   Model device: {next(model.parameters()).device}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define OCR Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "def get_ocr_prompt():\n",
    "    \"\"\"Get optimized prompt for Portuguese newspaper OCR\"\"\"\n",
    "    return \"\"\"Please output the layout information from this Portuguese newspaper page image, including each layout element's bbox, its category, and the corresponding text content within the bbox.\n",
    "\n",
    "1. Bbox format: [x1, y1, x2, y2]\n",
    "\n",
    "2. Layout Categories: The possible categories are ['Caption', 'Footnote', 'Formula', 'List-item', 'Page-footer', 'Page-header', 'Picture', 'Section-header', 'Table', 'Text', 'Title'].\n",
    "\n",
    "3. Text Extraction & Formatting Rules:\n",
    "    - Picture: For the 'Picture' category, the text field should be omitted.\n",
    "    - Formula: Format its text as LaTeX.\n",
    "    - Table: Format its text as HTML.\n",
    "    - All Others (Text, Title, etc.): Format their text as Markdown.\n",
    "\n",
    "4. Constraints:\n",
    "    - The output text must be the original Portuguese text from the image, with no translation.\n",
    "    - All layout elements must be sorted according to human reading order.\n",
    "\n",
    "5. Final Output: The entire output must be a single JSON object.\"\"\"\n",
    "\n",
    "\n",
    "def process_image(image_path, model, processor):\n",
    "    \"\"\"Process a single newspaper scan with OCR\"\"\"\n",
    "    try:\n",
    "        prompt = get_ocr_prompt()\n",
    "        \n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \"image\": str(image_path)},\n",
    "                    {\"type\": \"text\", \"text\": prompt}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Prepare inputs\n",
    "        text = processor.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        \n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "        inputs = processor(\n",
    "            text=[text],\n",
    "            images=image_inputs,\n",
    "            videos=video_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "        \n",
    "        # Generate OCR output\n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=24000)\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids):]\n",
    "            for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        \n",
    "        output_text = processor.batch_decode(\n",
    "            generated_ids_trimmed,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=False\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"image_path\": str(image_path),\n",
    "            \"text\": output_text[0],\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"success\": True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"image_path\": str(image_path),\n",
    "            \"error\": str(e),\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"success\": False\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ OCR functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Find Images to Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Check if directory exists\n",
    "data_path = Path(DATA_DIR)\n",
    "\n",
    "if not data_path.exists():\n",
    "    print(f\"‚ùå Directory does not exist: {DATA_DIR}\")\n",
    "    print(\"\\nPlease check:\")\n",
    "    print(\"1. Did you mount Google Drive in Cell 2?\")\n",
    "    print(\"2. Is the path correct? Update DRIVE_BASE in Cell 2\")\n",
    "    print(\"3. Did you upload images to Google Drive?\")\n",
    "    print(f\"\\nTrying to list parent directory...\")\n",
    "    parent = data_path.parent\n",
    "    if parent.exists():\n",
    "        print(f\"\\nContents of {parent}:\")\n",
    "        for item in parent.iterdir():\n",
    "            print(f\"  {'[DIR]' if item.is_dir() else '[FILE]'} {item.name}\")\n",
    "else:\n",
    "    print(f\"‚úì Directory exists: {DATA_DIR}\")\n",
    "    \n",
    "    # Show what's in the directory\n",
    "    print(f\"\\nContents of {DATA_DIR}:\")\n",
    "    items = list(data_path.iterdir())[:20]  # Show first 20 items\n",
    "    if not items:\n",
    "        print(\"  (empty directory)\")\n",
    "    else:\n",
    "        for item in items:\n",
    "            print(f\"  {'[DIR]' if item.is_dir() else '[FILE]'} {item.name}\")\n",
    "        if len(list(data_path.iterdir())) > 20:\n",
    "            print(f\"  ... and {len(list(data_path.iterdir())) - 20} more items\")\n",
    "    \n",
    "    # Find all newspaper scans (supports multiple formats)\n",
    "    image_files = []\n",
    "    \n",
    "    # Search for common image formats\n",
    "    print(f\"\\nSearching for images...\")\n",
    "    for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
    "        found = list(data_path.glob(f'**/{ext}'))\n",
    "        if found:\n",
    "            print(f\"  Found {len(found)} {ext} files\")\n",
    "        image_files.extend(found)\n",
    "    \n",
    "    image_files = sorted(image_files)\n",
    "    \n",
    "    print(f\"\\nTotal: {len(image_files)} images found\")\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(\"\\n‚ùå No images found!\")\n",
    "        print(f\"\\nExpected structure:\")\n",
    "        print(f\"  {DATA_DIR}/\")\n",
    "        print(f\"  ‚îî‚îÄ‚îÄ YYYY/\")\n",
    "        print(f\"      ‚îî‚îÄ‚îÄ MM/\")\n",
    "        print(f\"          ‚îî‚îÄ‚îÄ DD/\")\n",
    "        print(f\"              ‚îú‚îÄ‚îÄ image1.jpg\")\n",
    "        print(f\"              ‚îî‚îÄ‚îÄ image2.png\")\n",
    "        print(f\"\\nOr flat structure:\")\n",
    "        print(f\"  {DATA_DIR}/\")\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ image1.jpg\")\n",
    "        print(f\"  ‚îî‚îÄ‚îÄ image2.png\")\n",
    "    else:\n",
    "        # Show format breakdown\n",
    "        from collections import Counter\n",
    "        formats = Counter(f.suffix.lower() for f in image_files)\n",
    "        print(f\"\\n   Image formats: {dict(formats)}\")\n",
    "        \n",
    "        print(f\"\\nFirst image: {image_files[0]}\")\n",
    "        print(f\"Last image: {image_files[-1]}\")\n",
    "        \n",
    "        # Estimate processing time\n",
    "        minutes_per_image = 0.5  # Rough estimate for T4 GPU\n",
    "        total_minutes = len(image_files) * minutes_per_image\n",
    "        print(f\"\\nEstimated processing time: {total_minutes/60:.1f} hours\")\n",
    "        \n",
    "        if total_minutes > 600:  # 10 hours\n",
    "            print(\"\\n‚ö†Ô∏è  WARNING: This will take >10 hours\")\n",
    "            print(\"   Consider processing in batches or limiting the number of images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Process Images (with Progress Tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import time\n",
    "\n",
    "# CONFIGURATION\n",
    "BATCH_LIMIT = 100  # Process only first N images (change to None for all)\n",
    "SAVE_EVERY = 10    # Save progress every N images\n",
    "\n",
    "# Limit images if specified\n",
    "images_to_process = image_files[:BATCH_LIMIT] if BATCH_LIMIT else image_files\n",
    "\n",
    "print(f\"Processing {len(images_to_process)} images...\")\n",
    "print(f\"Output will be saved to: {OUTPUT_DIR}\\n\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Process images\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "for idx, image_path in enumerate(tqdm(images_to_process, desc=\"Processing\")):\n",
    "    # Process image\n",
    "    result = process_image(image_path, model, processor)\n",
    "    results.append(result)\n",
    "    \n",
    "    # Save individual result\n",
    "    if result[\"success\"]:\n",
    "        image_name = Path(image_path).stem\n",
    "        \n",
    "        # Save JSON\n",
    "        json_path = Path(OUTPUT_DIR) / f\"{image_name}_ocr.json\"\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        # Save text only\n",
    "        txt_path = Path(OUTPUT_DIR) / f\"{image_name}_ocr.txt\"\n",
    "        with open(txt_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(result.get('text', ''))\n",
    "    \n",
    "    # Save progress periodically\n",
    "    if (idx + 1) % SAVE_EVERY == 0:\n",
    "        progress_path = Path(OUTPUT_DIR) / \"batch_results.json\"\n",
    "        with open(progress_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # Memory management\n",
    "    if (idx + 1) % 50 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Final save\n",
    "batch_path = Path(OUTPUT_DIR) / \"batch_results.json\"\n",
    "with open(batch_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Statistics\n",
    "elapsed_time = time.time() - start_time\n",
    "successful = sum(1 for r in results if r[\"success\"])\n",
    "failed = len(results) - successful\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROCESSING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total images: {len(results)}\")\n",
    "print(f\"Successful: {successful}\")\n",
    "print(f\"Failed: {failed}\")\n",
    "print(f\"Total time: {elapsed_time/60:.1f} minutes\")\n",
    "print(f\"Average time per image: {elapsed_time/len(results):.1f} seconds\")\n",
    "print(f\"\\nResults saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. View Sample Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample result\n",
    "if successful > 0:\n",
    "    sample_result = next(r for r in results if r[\"success\"])\n",
    "    \n",
    "    print(\"Sample OCR Result:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Image: {sample_result['image_path']}\")\n",
    "    print(\"\\nExtracted Text (first 500 characters):\")\n",
    "    print(\"-\" * 60)\n",
    "    print(sample_result['text'][:500])\n",
    "    print(\"-\" * 60)\n",
    "else:\n",
    "    print(\"No successful results to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cleanup & Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Free GPU memory\n",
    "del model\n",
    "del processor\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(\"‚úÖ GPU memory cleared\")\n",
    "print(f\"\\nüìÅ All results saved to Google Drive: {OUTPUT_DIR}\")\n",
    "print(\"\\nYou can now:\")\n",
    "print(\"1. Access results from Google Drive on any device\")\n",
    "print(\"2. Download the ocr_output folder to your local machine\")\n",
    "print(\"3. Run this notebook again to process more images\")\n",
    "print(f\"\\nExecution completed: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Zip Results for Easy Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to create a ZIP file of all results\n",
    "# !cd {DRIVE_BASE} && zip -r ocr_output.zip ocr_output/\n",
    "# print(f\"‚úÖ Created: {DRIVE_BASE}/ocr_output.zip\")\n",
    "# print(\"Download this file from Google Drive\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
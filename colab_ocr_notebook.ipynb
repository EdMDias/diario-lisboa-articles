{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Di√°rio de Lisboa - OCR Processing on Google Colab\n",
        "\n",
        "**Purpose**: Process newspaper scans with DOTS OCR using Colab's free GPU\n",
        "\n",
        "**Setup**:\n",
        "1. Runtime > Change runtime type > **GPU (T4)** > Save\n",
        "2. Upload newspaper scans to Google Drive\n",
        "3. Run all cells\n",
        "\n",
        "**Note**: Free Colab has 12-hour session limit and ~15GB VRAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & GPU Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "from datetime import datetime\n",
        "\n",
        "print(f\"Execution started: {datetime.now()}\")\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "\n",
        "# Check GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"\\n‚úÖ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    print(\"\\n‚ùå WARNING: GPU not available, OCR will be VERY slow\")\n",
        "    print(\"   Go to: Runtime > Change runtime type > GPU\")\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(f\"\\nDevice: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Configure paths - CHANGE THESE TO MATCH YOUR DRIVE STRUCTURE\n",
        "DRIVE_BASE = '/content/drive/MyDrive/diario-lisbon'\n",
        "DATA_DIR = f'{DRIVE_BASE}/data'  # Where your newspaper scans are\n",
        "OUTPUT_DIR = f'{DRIVE_BASE}/ocr_output'  # Where OCR results will be saved\n",
        "\n",
        "print(f\"‚úÖ Google Drive mounted\")\n",
        "print(f\"   Data directory: {DATA_DIR}\")\n",
        "print(f\"   Output directory: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install DOTS OCR and dependencies\n",
        "print(\"Installing dependencies (this takes ~3-5 minutes)...\")\n",
        "\n",
        "# Install PyTorch with CUDA support (usually pre-installed in Colab)\n",
        "!pip install -q torch torchvision torchaudio\n",
        "\n",
        "# Install transformers and dependencies\n",
        "!pip install -q transformers>=4.45.0 accelerate>=0.21.0\n",
        "!pip install -q qwen-vl-utils Pillow tqdm\n",
        "\n",
        "# Install DOTS OCR from GitHub\n",
        "!pip install -q git+https://github.com/rednote-hilab/dots.ocr.git\n",
        "\n",
        "print(\"\\n‚úÖ All dependencies installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Download DOTS OCR Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoProcessor\n",
        "import torch\n",
        "\n",
        "MODEL_ID = \"rednote-hilab/dots.ocr\"\n",
        "\n",
        "print(f\"Loading DOTS OCR model: {MODEL_ID}\")\n",
        "print(\"This will download ~8-10GB on first run (cached for future runs)\")\n",
        "print(\"Please wait...\\n\")\n",
        "\n",
        "# Load model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# Load processor\n",
        "processor = AutoProcessor.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Model loaded successfully\")\n",
        "print(f\"   Model parameters: {sum(p.numel() for p in model.parameters()) / 1e9:.2f}B\")\n",
        "print(f\"   Model device: {next(model.parameters()).device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Define OCR Processing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from qwen_vl_utils import process_vision_info\n",
        "\n",
        "def get_ocr_prompt():\n",
        "    \"\"\"Get optimized prompt for Portuguese newspaper OCR\"\"\"\n",
        "    return \"\"\"Please output the layout information from this Portuguese newspaper page image, including each layout element's bbox, its category, and the corresponding text content within the bbox.\n",
        "\n",
        "1. Bbox format: [x1, y1, x2, y2]\n",
        "\n",
        "2. Layout Categories: The possible categories are ['Caption', 'Footnote', 'Formula', 'List-item', 'Page-footer', 'Page-header', 'Picture', 'Section-header', 'Table', 'Text', 'Title'].\n",
        "\n",
        "3. Text Extraction & Formatting Rules:\n",
        "    - Picture: For the 'Picture' category, the text field should be omitted.\n",
        "    - Formula: Format its text as LaTeX.\n",
        "    - Table: Format its text as HTML.\n",
        "    - All Others (Text, Title, etc.): Format their text as Markdown.\n",
        "\n",
        "4. Constraints:\n",
        "    - The output text must be the original Portuguese text from the image, with no translation.\n",
        "    - All layout elements must be sorted according to human reading order.\n",
        "\n",
        "5. Final Output: The entire output must be a single JSON object.\"\"\"\n",
        "\n",
        "\n",
        "def process_image(image_path, model, processor):\n",
        "    \"\"\"Process a single newspaper scan with OCR\"\"\"\n",
        "    try:\n",
        "        prompt = get_ocr_prompt()\n",
        "        \n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"image\", \"image\": str(image_path)},\n",
        "                    {\"type\": \"text\", \"text\": prompt}\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "        \n",
        "        # Prepare inputs\n",
        "        text = processor.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "        \n",
        "        image_inputs, video_inputs = process_vision_info(messages)\n",
        "        inputs = processor(\n",
        "            text=[text],\n",
        "            images=image_inputs,\n",
        "            videos=video_inputs,\n",
        "            padding=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        inputs = inputs.to(\"cuda\")\n",
        "        \n",
        "        # Generate OCR output\n",
        "        generated_ids = model.generate(**inputs, max_new_tokens=24000)\n",
        "        generated_ids_trimmed = [\n",
        "            out_ids[len(in_ids):]\n",
        "            for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "        ]\n",
        "        \n",
        "        output_text = processor.batch_decode(\n",
        "            generated_ids_trimmed,\n",
        "            skip_special_tokens=True,\n",
        "            clean_up_tokenization_spaces=False\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            \"image_path\": str(image_path),\n",
        "            \"text\": output_text[0],\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"success\": True\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"image_path\": str(image_path),\n",
        "            \"error\": str(e),\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"success\": False\n",
        "        }\n",
        "\n",
        "print(\"‚úÖ OCR functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Find Images to Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Find all newspaper scans\n",
        "data_path = Path(DATA_DIR)\n",
        "image_files = sorted(data_path.glob('**/*.jpg'))\n",
        "\n",
        "print(f\"Found {len(image_files)} images to process\")\n",
        "\n",
        "if len(image_files) == 0:\n",
        "    print(\"\\n‚ùå No images found!\")\n",
        "    print(f\"   Check that images are in: {DATA_DIR}\")\n",
        "    print(\"   Expected structure: data/YYYY/MM/DD/*.jpg\")\n",
        "else:\n",
        "    print(f\"\\nFirst image: {image_files[0]}\")\n",
        "    print(f\"Last image: {image_files[-1]}\")\n",
        "    \n",
        "    # Estimate processing time\n",
        "    minutes_per_image = 0.5  # Rough estimate for T4 GPU\n",
        "    total_minutes = len(image_files) * minutes_per_image\n",
        "    print(f\"\\nEstimated processing time: {total_minutes/60:.1f} hours\")\n",
        "    \n",
        "    if total_minutes > 600:  # 10 hours\n",
        "        print(\"\\n‚ö†Ô∏è  WARNING: This will take >10 hours\")\n",
        "        print(\"   Consider processing in batches or limiting the number of images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Process Images (with Progress Tracking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import time\n",
        "\n",
        "# CONFIGURATION\n",
        "BATCH_LIMIT = 100  # Process only first N images (change to None for all)\n",
        "SAVE_EVERY = 10    # Save progress every N images\n",
        "\n",
        "# Limit images if specified\n",
        "images_to_process = image_files[:BATCH_LIMIT] if BATCH_LIMIT else image_files\n",
        "\n",
        "print(f\"Processing {len(images_to_process)} images...\")\n",
        "print(f\"Output will be saved to: {OUTPUT_DIR}\\n\")\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Process images\n",
        "results = []\n",
        "start_time = time.time()\n",
        "\n",
        "for idx, image_path in enumerate(tqdm(images_to_process, desc=\"Processing\")):\n",
        "    # Process image\n",
        "    result = process_image(image_path, model, processor)\n",
        "    results.append(result)\n",
        "    \n",
        "    # Save individual result\n",
        "    if result[\"success\"]:\n",
        "        image_name = Path(image_path).stem\n",
        "        \n",
        "        # Save JSON\n",
        "        json_path = Path(OUTPUT_DIR) / f\"{image_name}_ocr.json\"\n",
        "        with open(json_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(result, f, ensure_ascii=False, indent=2)\n",
        "        \n",
        "        # Save text only\n",
        "        txt_path = Path(OUTPUT_DIR) / f\"{image_name}_ocr.txt\"\n",
        "        with open(txt_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(result.get('text', ''))\n",
        "    \n",
        "    # Save progress periodically\n",
        "    if (idx + 1) % SAVE_EVERY == 0:\n",
        "        progress_path = Path(OUTPUT_DIR) / \"batch_results.json\"\n",
        "        with open(progress_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "    \n",
        "    # Memory management\n",
        "    if (idx + 1) % 50 == 0:\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# Final save\n",
        "batch_path = Path(OUTPUT_DIR) / \"batch_results.json\"\n",
        "with open(batch_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# Statistics\n",
        "elapsed_time = time.time() - start_time\n",
        "successful = sum(1 for r in results if r[\"success\"])\n",
        "failed = len(results) - successful\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PROCESSING COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total images: {len(results)}\")\n",
        "print(f\"Successful: {successful}\")\n",
        "print(f\"Failed: {failed}\")\n",
        "print(f\"Total time: {elapsed_time/60:.1f} minutes\")\n",
        "print(f\"Average time per image: {elapsed_time/len(results):.1f} seconds\")\n",
        "print(f\"\\nResults saved to: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. View Sample Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display a sample result\n",
        "if successful > 0:\n",
        "    sample_result = next(r for r in results if r[\"success\"])\n",
        "    \n",
        "    print(\"Sample OCR Result:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Image: {sample_result['image_path']}\")\n",
        "    print(\"\\nExtracted Text (first 500 characters):\")\n",
        "    print(\"-\" * 60)\n",
        "    print(sample_result['text'][:500])\n",
        "    print(\"-\" * 60)\n",
        "else:\n",
        "    print(\"No successful results to display\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Cleanup & Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "# Free GPU memory\n",
        "del model\n",
        "del processor\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(\"‚úÖ GPU memory cleared\")\n",
        "print(f\"\\nüìÅ All results saved to Google Drive: {OUTPUT_DIR}\")\n",
        "print(\"\\nYou can now:\")\n",
        "print(\"1. Access results from Google Drive on any device\")\n",
        "print(\"2. Download the ocr_output folder to your local machine\")\n",
        "print(\"3. Run this notebook again to process more images\")\n",
        "print(f\"\\nExecution completed: {datetime.now()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Zip Results for Easy Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to create a ZIP file of all results\n",
        "# !cd {DRIVE_BASE} && zip -r ocr_output.zip ocr_output/\n",
        "# print(f\"‚úÖ Created: {DRIVE_BASE}/ocr_output.zip\")\n",
        "# print(\"Download this file from Google Drive\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
